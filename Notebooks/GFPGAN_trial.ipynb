{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawansharmaaaa/Wav2Lip_Mod/blob/master/GFPGAN_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12q3Emwdqp5X"
      },
      "outputs": [],
      "source": [
        "!pip install basicsr facexlib realesrgan gfpgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIfC7G3brHYV"
      },
      "outputs": [],
      "source": [
        "from gfpgan import GFPGANer\n",
        "import realesrgan\n",
        "import cv2\n",
        "import torch\n",
        "from basicsr.utils import imwrite\n",
        "import numpy as np\n",
        "\n",
        "arch = 'clean'\n",
        "channel_multiplier = 2\n",
        "model_name = 'GFPGANv1.4'\n",
        "url = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth'\n",
        "\n",
        "restorer = GFPGANer(\n",
        "    model_path = url,\n",
        "    upscale = 2,\n",
        "    arch = 'clean',\n",
        "    channel_multiplier=2,\n",
        "    bg_upsampler=None\n",
        ")\n",
        "\n",
        "im_path = \"/content/10045.png\"\n",
        "input_img = cv2.imread(im_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "c_faces, res_faces, res_imgs = restorer.enhance(\n",
        "    input_img,\n",
        "    has_aligned=True,\n",
        "    only_center_face=True,\n",
        "    paste_back=True,\n",
        "    weight = 0.6\n",
        ")\n",
        "\n",
        "res = np.array(res_imgs)\n",
        "print(res)\n",
        "cv2.imwrite('/out.png', res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QPH1UIrzkRD"
      },
      "source": [
        "#TRIAL AND ERROR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDLmcaR7znD9",
        "outputId": "93b19b9b-f95c-4e89-a0d7-54fb20e7d1aa"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "!cd GFPGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bkAWnWSzuD9",
        "outputId": "b373f55c-f497-4dd1-cf13-8b7142acc3b9"
      },
      "outputs": [],
      "source": [
        "!pip install basicsr facexlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F193o3k9z6ga",
        "outputId": "36dd0af9-0180-4c03-dc43-24edca3b3be9"
      },
      "outputs": [],
      "source": [
        "!cd GFPGAN && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lksYC-4N1iqE",
        "outputId": "88c819b7-1760-42af-b1d9-8f927e84bb4a"
      },
      "outputs": [],
      "source": [
        "!cd GFPGAN && python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOyZ7DAN0Ht8",
        "outputId": "5c083848-2829-48b7-b89c-b12efaebf28a"
      },
      "outputs": [],
      "source": [
        "!pip install realesrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9z8IvMm0MPi",
        "outputId": "b1be3867-0026-4692-ee09-0fd72bcc2319"
      },
      "outputs": [],
      "source": [
        "!cd GFPGAN && wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQclq04B0WFH"
      },
      "outputs": [],
      "source": [
        "!cd GFPGAN && python inference_gfpgan.py -i /content/GFPGAN/inputs/test2.jpg -o results/new -v 1.3 -s 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZBKqSViD5_L",
        "outputId": "dd92d192-f469-4427-ac02-af40b511e716"
      },
      "outputs": [],
      "source": [
        "!pip install gfpgan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPqP6ZzJ_ueK"
      },
      "source": [
        "#FRAMER.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UV6K6eTFhOW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/GFPGAN')\n",
        "!cd GFPGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YF6L-bst_tz4",
        "outputId": "b38c882e-8a8d-4fb3-fbcf-10774aa20cab"
      },
      "outputs": [],
      "source": [
        "!cd GFPGAN\n",
        "import cv2\n",
        "import os\n",
        "from gfpgan import GFPGANer\n",
        "import torch\n",
        "\n",
        "\n",
        "def divide_video_into_frames(video_path, output_dir):\n",
        "    #LOAD REALESRGAN\n",
        "    upsample_bg = 'realesrgan'\n",
        "    if upsample_bg == 'realesrgan':\n",
        "        if not torch.cuda.is_available():  # CPU\n",
        "            import warnings\n",
        "            warnings.warn('The unoptimized RealESRGAN is slow on CPU. We do not use it. '\n",
        "                          'If you really want to use it, please modify the corresponding codes.')\n",
        "            bg_upsampler = None\n",
        "        else:\n",
        "            from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "            from realesrgan import RealESRGANer\n",
        "            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "            bg_upsampler = RealESRGANer(\n",
        "                scale=2,\n",
        "                model_path='https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth',\n",
        "                model=model,\n",
        "                tile=0,\n",
        "                tile_pad=10,\n",
        "                pre_pad=0,\n",
        "                half=True)  # need to set False in CPU mode\n",
        "    else:\n",
        "        bg_upsampler = None\n",
        "\n",
        "    #LOAD GFPGAN\n",
        "    arch = 'clean'\n",
        "    channel_multiplier = 2\n",
        "    model_name = 'GFPGANv1.3'\n",
        "    url = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth'\n",
        "\n",
        "    restorer = GFPGANer(\n",
        "        model_path=url,\n",
        "        upscale=2,\n",
        "        arch=arch,\n",
        "        channel_multiplier=channel_multiplier,\n",
        "        bg_upsampler=bg_upsampler)\n",
        "\n",
        "    # Get the video capture object\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the number of frames in the video\n",
        "    num_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Iterate over the frames in the video\n",
        "    for i in range(num_frames):\n",
        "        # Read the frame from the video\n",
        "        success, frame = video_capture.read()\n",
        "\n",
        "        # If the frame was read successfully, save it\n",
        "        if success:\n",
        "            frame_name = os.path.join(output_dir, str(i) + \".jpg\")\n",
        "            cropped_faces, restored_faces, restored_img = restorer.enhance(\n",
        "              frame,\n",
        "              has_aligned=False,\n",
        "              only_center_face=False,\n",
        "              paste_back=True,\n",
        "              weight=0.5)\n",
        "\n",
        "            cv2.imwrite(frame_name, restored_img)\n",
        "\n",
        "    # Close the video capture object\n",
        "    video_capture.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the video path and output directory\n",
        "    video_path = \"/content/result_voice_theek.mp4\"\n",
        "    output_dir = \"/content/Frames\"\n",
        "\n",
        "    # Divide the video into frames\n",
        "    divide_video_into_frames(video_path, output_dir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMavVpvBVVZdqAovhNfcY1Q",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
