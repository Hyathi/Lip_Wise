{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pawansharmaaaa/Wav2Lip_Mod/blob/master/GFPGAN_Wav2Lip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QPH1UIrzkRD"
      },
      "source": [
        "#Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnHM2wvud_g9"
      },
      "source": [
        "Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qciH4PsUazL_",
        "outputId": "f85f3d5d-402c-4290-9d6b-d092d1641d85"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3cShHJ9nTb_"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuLbKrST5etk"
      },
      "outputs": [],
      "source": [
        "!cp -ri \"/content/drive/MyDrive/W2L_GFPMod/TAudio.wav\" \"/content/drive/MyDrive/W2L_GFPMod/unfiltered_input.mp4\" /content/Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgOmJn0-eD4c"
      },
      "source": [
        "Wav2Lip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlOPNDG-f6n9",
        "outputId": "8eef9d66-7225-4247-8f00-89779706bb37"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pawansharmaaaa/Wav2Lip_Mod.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-TvJSOOgDuN"
      },
      "outputs": [],
      "source": [
        "!cp -ri \"/content/drive/MyDrive/W2L_GFPMod/wav2lip.pth\" \"/content/drive/MyDrive/W2L_GFPMod/wav2lip_gan.pth\" /content/Wav2Lip_Mod/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooh28vw-Uvd3",
        "outputId": "b1754dca-153c-49d5-ccaa-5e16b58eb6cd"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip_Mod && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjN84E2EtvAd"
      },
      "source": [
        "**DEPRECATED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Gp5rgX2gily"
      },
      "outputs": [],
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip_Mod/face_detection/detection/sfd/s3fd.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg1Q8kdid7fa"
      },
      "source": [
        "GFPGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDLmcaR7znD9"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod && git clone https://github.com/TencentARC/GFPGAN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bkAWnWSzuD9"
      },
      "outputs": [],
      "source": [
        "!pip install basicsr facexlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F193o3k9z6ga"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lksYC-4N1iqE"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOyZ7DAN0Ht8"
      },
      "outputs": [],
      "source": [
        "!pip install realesrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9z8IvMm0MPi"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQclq04B0WFH"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod/GFPGAN && python inference_gfpgan.py -i /content/GFPGAN/inputs/test2.jpg -o results/new -v 1.3 -s 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZBKqSViD5_L"
      },
      "outputs": [],
      "source": [
        "!pip install gfpgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONBjxcJX5PY9"
      },
      "outputs": [],
      "source": [
        "!cp -ri \"/content/Data/w2l_input_video.mp4\" /content/drive/MyDrive/Finalized_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbemEAJhui2"
      },
      "source": [
        "#**No Face Filter** *(Remove Frames Which do not contain faces from the Video)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2WqC9RbJvU8",
        "outputId": "90224caa-3d9c-4f4e-cade-3833b0a127fc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import gc\n",
        "import tqdm\n",
        "\n",
        "# Function to detect face in a frame\n",
        "def detect_face(frames):\n",
        "    batch_face_locations = face_recognition.batch_face_locations(frames, number_of_times_to_upsample=0)\n",
        "    return batch_face_locations\n",
        "\n",
        "# Open the video file for reading\n",
        "video_path = '/content/Data/unfiltered_input.mp4'\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create video writers for face.mp4\n",
        "face_writer = cv2.VideoWriter('/content/Data/filtered_input_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "batch_size = 16\n",
        "frames = []\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frames.append(frame)\n",
        "\n",
        "    if len(frames) == batch_size:\n",
        "      frames_mem = frames.copy()\n",
        "      batch_faces = detect_face(frames_mem)\n",
        "\n",
        "      for frame_no, face_locations in enumerate(tqdm.tqdm(batch_faces, total=batch_size)):\n",
        "        if len(face_locations) == 1:\n",
        "            # Write the frame to input_video.mp4 if a face is detected\n",
        "            pos_frame = cv2.cvtColor(frames_mem[frame_no], cv2.COLOR_RGB2BGR)\n",
        "            face_writer.write(pos_frame)\n",
        "      gc.collect()\n",
        "      frames = []\n",
        "\n",
        "# Release video capture, writers and clear garbage\n",
        "video_capture.release()\n",
        "face_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT0FwwmPnltV"
      },
      "source": [
        "#Running Wav2Lip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_av1IIc4PWN",
        "outputId": "17019324-c900-4edd-ada9-8a12ee1f8b9f"
      },
      "outputs": [],
      "source": [
        "!cd Wav2Lip_Mod && python inf_w2l.py --checkpoint_path checkpoints/wav2lip.pth --face \"/content/Data/filtered_input_video.mp4\" --audio \"/content/Data/TAudio.wav\" --resize_factor 2 --upscale"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "eFbemEAJhui2",
        "IPqP6ZzJ_ueK"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
