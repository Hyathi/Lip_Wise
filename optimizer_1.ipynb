{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is a part of https://github.com/pawansharmaaaa/Lip_Wise/ repository.\n",
    "import gradio as gr\n",
    "\n",
    "# Custom Modules\n",
    "import infer\n",
    "import file_check\n",
    "\n",
    "bg_upscalers = list(file_check.REAL_ESRGAN_MODEL_URL.keys())\n",
    "\n",
    "# Create interface\n",
    "inputs_for_image = [\n",
    "    gr.Image(type=\"filepath\", label=\"Image\"),\n",
    "    gr.Audio(type=\"filepath\", label=\"Audio\"),\n",
    "    gr.Number(value=0, label=\"Padding: Increase if getting black outlines\"),\n",
    "    gr.Checkbox(label = \"Perform 3D_alignment?\"),\n",
    "    gr.Radio([\"GFPGAN\", \"CodeFormer\"], value='CodeFormer', label=\"Face Restorer\"),\n",
    "    gr.Slider(minimum=1, maximum=60, step=1, value=25, label=\"FPS\"),\n",
    "    gr.Number(value=16, label=\"Mel Step Size\", interactive=False, visible=False),\n",
    "    gr.Slider(minimum=0.0, maximum=1.0, step=0.1, value=0.3, label=\"Weight\"),\n",
    "    gr.Checkbox(label = \"Upscale Background with REALESRGAN\", value=False),\n",
    "    gr.Dropdown(choices=bg_upscalers, label=\"REALESRGAN Model\", value=\"RealESRGAN_x2plus\")\n",
    "]\n",
    "output_for_image = gr.Video(sources='upload', label=\"Output\")\n",
    "\n",
    "image_Interface = gr.Interface(fn=infer.infer_image, inputs=inputs_for_image, outputs=output_for_image)\n",
    "\n",
    "inputs_for_video = [\n",
    "    gr.Video(sources='upload',label=\"Video\"),\n",
    "    gr.Audio(type=\"filepath\", label=\"Audio\"),\n",
    "    gr.Number(value=0, label=\"Padding: Increase if getting black outlines\"),\n",
    "    gr.Radio([\"GFPGAN\", \"CodeFormer\"], value='CodeFormer', label=\"Face Restorer\"),\n",
    "    gr.Number(value=16, label=\"Mel Step Size\", interactive=False, visible=False),\n",
    "    gr.Slider(minimum=0.0, maximum=1.0, step=0.1, value=0.3, label=\"Weight\"),\n",
    "    gr.Checkbox(label = \"Upscale Background with REALESRGAN\", value=False),\n",
    "    gr.Dropdown(choices=bg_upscalers, label=\"REALESRGAN Model\", value=\"RealESRGAN_x2plus\")\n",
    "]\n",
    "output_for_video = gr.Video(sources='upload', label=\"Output\")\n",
    "\n",
    "video_Interface = gr.Interface(fn=infer.infer_video, inputs=inputs_for_video, outputs=output_for_video)\n",
    "\n",
    "# Run interface\n",
    "ui = gr.TabbedInterface([image_Interface, video_Interface], ['Process Image', 'Process Video'],title=\"Lip-Wise\",theme='gradio/monochrome')\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = '''\n",
    "For CodeFormer:\n",
    "    \\n\\t0 for better quality, 1 for better identity\n",
    "\\nFor GFPGAN:\n",
    "    \\n\\t1 for better quality, 0 for better identity\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file is a part of https://github.com/pawansharmaaaa/Lip_Wise/ repository.\n",
    "import gradio as gr\n",
    "\n",
    "# Custom Modules\n",
    "import infer\n",
    "import file_check\n",
    "\n",
    "bg_upscalers = list(file_check.REAL_ESRGAN_MODEL_URL.keys())\n",
    "\n",
    "def render_dd(bg_upscale):\n",
    "    \n",
    "    return gr.Dropdown(\n",
    "                        choices=bg_upscalers,\n",
    "                        label=\"REALESRGAN Model\",\n",
    "                        value=\"RealESRGAN_x2plus\",\n",
    "                        info=\"Choose the model to use for upscaling the background.\",\n",
    "                        # Initially disabled and hidden\n",
    "                        visible=bg_upscale\n",
    "                    )\n",
    "\n",
    "def render_weight(face_restorer):\n",
    "    if face_restorer == \"CodeFormer\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.3,\n",
    "                            label=\"CodeFormer Weight\",\n",
    "                            info=\"0 for better quality, 1 for better identity.\"\n",
    "                        )\n",
    "    else:\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.5,\n",
    "                            label=\"GFPGAN Weight\",\n",
    "                            info=\"0 for better identity, 1 for better quality.\"\n",
    "                        )\n",
    "    \n",
    "# Theme\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=gr.themes.Color(c100=\"#efe7ff\", c200=\"#decefe\", c300=\"#ccb7fd\", c400=\"#ba9ffc\", c50=\"#ffffff\", c500=\"#a688fa\", c600=\"#836bc3\", c700=\"#61508e\", c800=\"#41365d\", c900=\"#241e30\", c950=\"#25242a\"),\n",
    "    secondary_hue=gr.themes.Color(c100=\"#e2e1e4\", c200=\"#c6c5c9\", c300=\"#aba9b0\", c400=\"#908d96\", c50=\"#ffffff\", c500=\"#76737e\", c600=\"#5e5b64\", c700=\"#46444b\", c800=\"#302f33\", c900=\"#1b1b1d\", c950=\"#25242a\"),\n",
    "    neutral_hue=gr.themes.Color(c100=\"#e1e1e1\", c200=\"#c4c4c4\", c300=\"#a7a7a7\", c400=\"#8c8c8c\", c50=\"#ffffff\", c500=\"#717171\", c600=\"#5a5a5a\", c700=\"#434343\", c800=\"#2e2e2e\", c900=\"#25242a\", c950=\"#1b1b1b\"),\n",
    "    spacing_size=\"md\",\n",
    "    radius_size=\"lg\",\n",
    ").set(\n",
    "    shadow_drop='*shadow_inset',\n",
    "    shadow_drop_lg='*button_shadow_hover',\n",
    "    body_background_fill=\"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(255,255,255,1) 0.3%, rgba(255,255,255,1) 90.2% );\",\n",
    "    # body_background_fill_dark=\"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(0,0,0,1) 0.3%, rgba(77,72,85,1) 90.2% );\",\n",
    "    body_background_fill_dark= \"linear-gradient(315deg, #0cbaba 0%, #380036 74%);\"\n",
    "    # body_background_fill_dark= \"linear-gradient(315deg, #7f5a83 0%, #0d324d 74%);\"\n",
    "\n",
    "    # body_background_fill_dark= \"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(74,98,110,1) 0.3%, rgba(30,33,48,1) 90.2% );\",\n",
    "    # body_background_fill_dark= \"-webkit-linear-gradient(to right, #2C5364, #203A43, #0F2027);\",\n",
    "    # body_background_fill_dark= \"linear-gradient(to right, #2C5364, #203A43, #0F2027);\"\n",
    ")\n",
    "\n",
    "head_html = f'''\n",
    "<head class>\n",
    "  <meta author=\"Pawan Sharma\">\n",
    "  <meta charset=\"utf-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "</head>\n",
    "'''\n",
    "\n",
    "# Create interface\n",
    "\n",
    "with gr.Blocks(title='Lip-Wise', css=r\"E:\\Lip_Wise\\style.css\", head=head_html, theme=theme) as demo:\n",
    "    with gr.Row(elem_classes=[\"row\"]):\n",
    "        gr.HTML(\n",
    "            '''\n",
    "            <header>\n",
    "            <div class=\"header-left\">\n",
    "                <h1>Lip Wise</h1>\n",
    "                <h2>Wise Enhancements for Wav2Lip</h2>\n",
    "            </div>\n",
    "            <div class=\"header-right\">\n",
    "                <img src=\"https://github.com/pawansharmaaaa/Lip_Wise/assets/56242483/5bc1b8af-879a-414b-b54a-db605a53c8f7\" alt=\"Logo\">\n",
    "            </div>\n",
    "            </header>\n",
    "            '''\n",
    "        )\n",
    "    with gr.Tab(label=\"Process Image\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Row(elem_classes=[\"row\"]):\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# INPUTS\")\n",
    "                with gr.Accordion(label=\"Input Image and Audio\", open=True, elem_classes=[\"inp_group\", \"accordion\"]):\n",
    "                    image_input = gr.Image(type=\"filepath\", label=\"Image\", container=True, elem_id = \"inp_group\")\n",
    "                    audio_input = gr.Audio(type=\"filepath\", label=\"Audio\", container=True, elem_id = \"inp_group\")\n",
    "\n",
    "                with gr.Accordion(label=\"Options\", open=True, elem_classes=[\"opt_group\", \"accordion\"]):\n",
    "                    with gr.Group():\n",
    "                        with gr.Row():\n",
    "                            fps = gr.Slider(minimum=1, maximum=60, step=1, value=25, label=\"FPS\", info=\"Desired Frames per second (FPS) of the output video.\")\n",
    "                            padding = gr.Slider(minimum=0, maximum=60, step=1, value=0, label=\"Padding\", info=\"Increase if getting black outlines. The Value is in Pixels.\")\n",
    "                        with gr.Row():\n",
    "                            alignment = gr.Checkbox(label = \"Perform 3D_alignment\", info = \"This will improve the quality of the lip sync, but the output will be different from the original video.\")\n",
    "                            upscale_bg = gr.Checkbox(label = \"Upscale Background with REALESRGAN\", value=False, info=\"This will improve the quality of the video, but will take longer to process.\")\n",
    "                        with gr.Row():\n",
    "                            face_restorer = gr.Radio([\"GFPGAN\", \"CodeFormer\"], value='CodeFormer', label=\"Face Restorer\", info=\"GFPGAN is faster, but CodeFormer is more accurate.\", interactive=True)\n",
    "                            bg_model = gr.Dropdown(choices=bg_upscalers, label=\"REALESRGAN Model\", value=\"RealESRGAN_x2plus\", info=\"Choose the model to use for upscaling the background.\", visible=False)\n",
    "                        with gr.Row():\n",
    "                            with gr.Column():\n",
    "                                mel_step_size = gr.Number(value=16, label=\"Mel Step Size\", interactive=False, visible=False)\n",
    "                                weight = render_weight(face_restorer)\n",
    "                                upscale_bg.select(render_dd, upscale_bg, bg_model)\n",
    "                                face_restorer.select(render_weight, face_restorer, weight)\n",
    "                \n",
    "                process = gr.Button(value=\"Process Image\", variant=\"primary\", elem_id=\"gen-button\")\n",
    "\n",
    "\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# OUTPUT\")\n",
    "                image_output = gr.Video(sources='upload', label=\"Output\", elem_classes=[\"output\"])\n",
    "\n",
    "                process.click(infer.infer_image, [image_input, audio_input, padding, alignment, face_restorer, fps, mel_step_size, weight, upscale_bg, bg_model], [image_output])\n",
    "\n",
    "    with gr.Tab(label=\"Process Video\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Row(elem_classes=[\"row\"]):\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# INPUTS\")\n",
    "                with gr.Accordion(\"Input Video and Audio\", open=True, elem_classes=[\"inp_group\", \"accordion\"]):\n",
    "                    video_input = gr.Video(sources='upload',label=\"Video\")\n",
    "                    audio_input = gr.Audio(type=\"filepath\", label=\"Audio\")\n",
    "                \n",
    "                with gr.Accordion(label=\"Options\", open=True, elem_classes=[\"opt_group\", \"accordion\"]):\n",
    "                    with gr.Group():\n",
    "                        with gr.Column():\n",
    "                            padding = gr.Slider(minimum=0, maximum=60, step=1, value=0, label=\"Padding\", info=\"Increase if getting black outlines. The Value is in Pixels.\", elem_id=\"slider\")\n",
    "                            face_restorer = gr.Radio([\"GFPGAN\", \"CodeFormer\"], value='CodeFormer', label=\"Face Restorer\", info=\"GFPGAN is faster, but CodeFormer is more accurate.\")\n",
    "                            mel_step_size = gr.Number(value=16, label=\"Mel Step Size\", interactive=False, visible=False)\n",
    "                            weight = render_weight(face_restorer)\n",
    "                        with gr.Column():\n",
    "                            upscale_bg = gr.Checkbox(label = \"Upscale Background with REALESRGAN\", value=False, info=\"This will improve the quality of the video, but will take longer to process.\")\n",
    "                            bg_model = gr.Dropdown(choices=bg_upscalers, label=\"REALESRGAN Model\", value=\"RealESRGAN_x2plus\", info=\"Choose the model to use for upscaling the background.\", visible=False)\n",
    "                            \n",
    "                            upscale_bg.select(render_dd, upscale_bg, bg_model)\n",
    "                            face_restorer.select(render_weight, face_restorer, weight)\n",
    "                    \n",
    "                process = gr.Button(value=\"Process Video\", variant=\"primary\", elem_id=\"gen-button\")\n",
    "\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# OUTPUT\")\n",
    "                video_output = gr.Video(sources='upload', label=\"Output\", elem_classes=[\"output\"])\n",
    "\n",
    "                process.click(infer.infer_video, [video_input, audio_input, padding, face_restorer, mel_step_size, weight, upscale_bg, bg_model], [video_output])\n",
    "\n",
    "    with gr.Tab(label=\"Guide\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Accordion(label=\"Tips For Better Results\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > - Optimal performance is achieved with a **clear image** featuring a person facing the camera, regardless of head angle. However, avoid **tilting in the z-direction** (3D-alignment can address this with certain considerations).\n",
    "            > - Ensure the image contains only **one person** with a prominently visible face.\n",
    "            > - Clear audio devoid of background noise enhances results significantly.\n",
    "            > - Note that **higher image resolution** necessitates **additional processing time**.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"Model Selection\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > ##### **CODEFORMER:**\n",
    "            >**Recommended Weight:** `0 for better quality, 1 for better identity.`\n",
    "            >>- CodeFormer employs a transformative architecture to restore facial features.\n",
    "            >>- While relatively slower, it boasts **higher accuracy**.\n",
    "            >>- Generally delivers superior results while **preserving skin texture**.\n",
    "            >>- In cases of peculiar artifacts, especially around the nose, consider using GFPGAN.\n",
    "            \n",
    "            > ##### **GFPGAN:**\n",
    "            >**Recommended Weight:** `0 for better identity, 1 for better quality.`\n",
    "            >>- GFPGAN, a faster model, relies on a GAN-based framework for facial restoration.\n",
    "            >>- Suggested for use **when CodeFormer exhibits undesirable artifacts**.\n",
    "            >>- However, it often sacrifices skin texture fidelity.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"3D Alignment\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > Enabling this feature **transforms** the image to ensure the person faces the camera directly. While enhancing lip sync quality, the output may diverge from the original video.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"Background Upscaling\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > - Activating this feature **enhances video quality** but prolongs processing time.\n",
    "            > - For most scenarios, RealESRGAN_x2plus is preferable due to its comparative speed.\n",
    "            > - Optimal results are achieved when combined with CodeFormer, except in cases of nose-related artifacts.\n",
    "            > - This feature effectively **eliminates video flickering**.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import file_check\n",
    "\n",
    "def render_dd(bg_upscale):\n",
    "    \n",
    "    return gr.Dropdown(\n",
    "                        choices=bg_upscalers,\n",
    "                        label=\"REALESRGAN Model\",\n",
    "                        value=\"RealESRGAN_x2plus\",\n",
    "                        info=\"Choose the model to use for upscaling the background.\",\n",
    "                        # Initially disabled and hidden\n",
    "                        visible=bg_upscale\n",
    "                    )\n",
    "\n",
    "def render_weight(face_restorer):\n",
    "    if face_restorer == \"CodeFormer\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.3,\n",
    "                            label=\"CodeFormer Weight\"\n",
    "                        )\n",
    "    else:\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.5,\n",
    "                            label=\"GFPGAN Weight\"\n",
    "                        )\n",
    "\n",
    "bg_upscalers = list(file_check.REAL_ESRGAN_MODEL_URL.keys())\n",
    "\n",
    "# Assuming you have necessary imports and definitions for bg_upscalers\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Tab(label=\"Process Video\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# INPUTS\")\n",
    "                with gr.Group():\n",
    "                    video_input = gr.Video(sources='upload', label=\"Video\")\n",
    "                    audio_input = gr.Audio(type=\"filepath\", label=\"Audio\")\n",
    "                with gr.Group():\n",
    "                    with gr.Row():\n",
    "                        padding = gr.Slider(\n",
    "                            minimum=1,\n",
    "                            maximum=60,\n",
    "                            step=1,\n",
    "                            value=0,\n",
    "                            label=\"Padding\",\n",
    "                            info=\"Increase if getting black outlines. The Value is in Pixels.\"\n",
    "                        )\n",
    "                        face_restorer = gr.Radio(\n",
    "                            [\"GFPGAN\", \"CodeFormer\"],\n",
    "                            value='CodeFormer',\n",
    "                            label=\"Face Restorer\",\n",
    "                            info=\"GFPGAN is faster, but CodeFormer is more accurate.\"\n",
    "                        )\n",
    "                        mel_step_size = gr.Number(\n",
    "                            value=16,\n",
    "                            label=\"Mel Step Size\",\n",
    "                            interactive=False,\n",
    "                            visible=False\n",
    "                        )\n",
    "                        weight = gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.3,\n",
    "                            label=\"Restorer Weight\"\n",
    "                        )\n",
    "                    with gr.Row():\n",
    "                        upscale_bg = gr.Checkbox(\n",
    "                            label=\"Upscale Background with REALESRGAN\",\n",
    "                            value=False,\n",
    "                            info=\"This will improve the quality of the video, but will take longer to process.\"\n",
    "                        )\n",
    "                        bg_model = gr.Dropdown(\n",
    "                            choices=bg_upscalers,\n",
    "                            label=\"REALESRGAN Model\",\n",
    "                            value=\"RealESRGAN_x2plus\",\n",
    "                            info=\"Choose the model to use for upscaling the background.\",\n",
    "                            # Initially disabled and hidden\n",
    "                            visible=False\n",
    "                        )\n",
    "                        upscale_bg.select(render_dd, upscale_bg, bg_model)\n",
    "\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# OUTPUT\")\n",
    "                image_output = gr.Video(sources='upload', label=\"Output\")\n",
    "\n",
    "    live = True\n",
    "\n",
    "ui.launch()\n",
    "\n",
    "# ... rest of your Gradio interface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Custom CSS\n",
    "custom_css = \"\"\"\n",
    "html, body {\n",
    "  font-family: JetBrains Mono, monospace;\n",
    "  margin: 0;\n",
    "  padding: 0;\n",
    "}\n",
    "\n",
    ".gradio-header {\n",
    "  background-color: #ffffff;\n",
    "  padding: 10px 20px;\n",
    "  display: flex;\n",
    "  justify-content: space-between;\n",
    "  align-items: center;\n",
    "}\n",
    "\n",
    ".gradio-header h1 {\n",
    "  font-size: 20px;\n",
    "  margin: 0;\n",
    "}\n",
    "\n",
    ".gradio-input {\n",
    "  margin-bottom: 15px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(css=custom_css, head=gr.HTML(\"\"\"\n",
    "        <h1>Calculator App</h1>\n",
    "    \"\"\")) as demo:\n",
    "    # Custom header\n",
    "\n",
    "    # Inputs\n",
    "    num1 = gr.Number(label=\"Number 1\")\n",
    "    num2 = gr.Number(label=\"Number 2\")\n",
    "\n",
    "    # Calculation\n",
    "    def add(n1, n2):\n",
    "        return n1 + n2\n",
    "\n",
    "    # Output\n",
    "    output = gr.Number(label=\"Result\")\n",
    "\n",
    "    num1.change(add, [num1, num2], output)\n",
    "    num2.change(add, [num1, num2], output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/* CSS HEX */\n",
    "--jet: #383838ff;\n",
    "--lemon-chiffon: #faf0caff;\n",
    "--eerie-black: #1e1e1eff;\n",
    "--red-cmyk: #ed1c24ff;\n",
    "--pumpkin: #fa7921ff;\n",
    "\n",
    "/* CSS HSL */\n",
    "--jet: hsla(0, 0%, 22%, 1);\n",
    "--lemon-chiffon: hsla(48, 83%, 89%, 1);\n",
    "--eerie-black: hsla(0, 0%, 12%, 1);\n",
    "--red-cmyk: hsla(358, 85%, 52%, 1);\n",
    "--pumpkin: hsla(24, 96%, 55%, 1);\n",
    "\n",
    "/* SCSS HEX */\n",
    "$jet: #383838ff;\n",
    "$lemon-chiffon: #faf0caff;\n",
    "$eerie-black: #1e1e1eff;\n",
    "$red-cmyk: #ed1c24ff;\n",
    "$pumpkin: #fa7921ff;\n",
    "\n",
    "/* SCSS HSL */\n",
    "$jet: hsla(0, 0%, 22%, 1);\n",
    "$lemon-chiffon: hsla(48, 83%, 89%, 1);\n",
    "$eerie-black: hsla(0, 0%, 12%, 1);\n",
    "$red-cmyk: hsla(358, 85%, 52%, 1);\n",
    "$pumpkin: hsla(24, 96%, 55%, 1);\n",
    "\n",
    "/* SCSS RGB */\n",
    "$jet: rgba(56, 56, 56, 1);\n",
    "$lemon-chiffon: rgba(250, 240, 202, 1);\n",
    "$eerie-black: rgba(30, 30, 30, 1);\n",
    "$red-cmyk: rgba(237, 28, 36, 1);\n",
    "$pumpkin: rgba(250, 121, 33, 1);\n",
    "\n",
    "/* SCSS Gradient */\n",
    "$gradient-top: linear-gradient(0deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-right: linear-gradient(90deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-bottom: linear-gradient(180deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-left: linear-gradient(270deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-top-right: linear-gradient(45deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-bottom-right: linear-gradient(135deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-top-left: linear-gradient(225deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-bottom-left: linear-gradient(315deg, #383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);\n",
    "$gradient-radial: radial-gradient(#383838ff, #faf0caff, #1e1e1eff, #ed1c24ff, #fa7921ff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title # Color Generator\n",
    "import colorsys\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def rgb_to_hex(rgb_color):\n",
    "    return ''.join([f'{i:02x}' for i in rgb_color])\n",
    "\n",
    "def generate_colors(primary_950):\n",
    "    primary_950_rgb = hex_to_rgb(primary_950[1:])  # Remove the '#' at the start\n",
    "    primary_950_hls = colorsys.rgb_to_hls(*[x/255.0 for x in primary_950_rgb])\n",
    "\n",
    "    colors = {}\n",
    "    colors_rgb = {}\n",
    "    for i in range(50, 1000, 50):\n",
    "        weight = i / 1000.0\n",
    "        lighter_color_hls = (primary_950_hls[0], max(0, min(1, weight)), primary_950_hls[2])\n",
    "        lighter_color_rgb = [int(x*255.0) for x in colorsys.hls_to_rgb(*lighter_color_hls)]\n",
    "        colors_rgb[f'primary_{i}'] = lighter_color_rgb\n",
    "        colors[f'primary_{i}'] = '#' + rgb_to_hex(lighter_color_rgb)\n",
    "\n",
    "    return colors, colors_rgb\n",
    "\n",
    "primary_950 = '#382bf0'  # Example input\n",
    "colors, colors_rgb = generate_colors(primary_950)\n",
    "for name, color in colors.items():\n",
    "    print(f'{name}: {color}')\n",
    "\n",
    "for name, color in colors_rgb.items():\n",
    "    print(f'{name}: {color}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary Hues\n",
    "\n",
    "primary_50: #e8e7fd\n",
    "primary_100: #d2cffb\n",
    "primary_150: #bbb7f9\n",
    "primary_200: #a59ff8\n",
    "primary_250: #8f87f6\n",
    "primary_300: #7870f4\n",
    "primary_350: #6258f3\n",
    "primary_400: #4c40f1\n",
    "primary_450: #3528ef\n",
    "primary_500: #1f10ee\n",
    "primary_550: #1c0fd6\n",
    "primary_600: #190dbe\n",
    "primary_650: #160ba6\n",
    "primary_700: #120a8e\n",
    "primary_750: #0f0877\n",
    "primary_800: #0c065f\n",
    "primary_850: #090547\n",
    "primary_900: #06032f\n",
    "primary_950: #030117\n",
    "primary_50: [232, 231, 253]\n",
    "primary_100: [210, 207, 251]\n",
    "primary_150: [187, 183, 249]\n",
    "primary_200: [165, 159, 248]\n",
    "primary_250: [143, 135, 246]\n",
    "primary_300: [120, 112, 244]\n",
    "primary_350: [98, 88, 243]\n",
    "primary_400: [76, 64, 241]\n",
    "primary_450: [53, 40, 239]\n",
    "primary_500: [31, 16, 238]\n",
    "primary_550: [28, 15, 214]\n",
    "primary_600: [25, 13, 190]\n",
    "primary_650: [22, 11, 166]\n",
    "primary_700: [18, 10, 142]\n",
    "primary_750: [15, 8, 119]\n",
    "primary_800: [12, 6, 95]\n",
    "primary_850: [9, 5, 71]\n",
    "primary_900: [6, 3, 47]\n",
    "primary_950: [3, 1, 23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primary_100: {'hex': '8b8b8b', 'rgb': array([139, 139, 139])}\n",
      "primary_200: {'hex': '717171', 'rgb': array([113, 113, 113])}\n",
      "primary_300: {'hex': '575757', 'rgb': array([87, 87, 87])}\n",
      "primary_400: {'hex': '3f3f3f', 'rgb': array([63, 63, 63])}\n",
      "primary_500: {'hex': '282828', 'rgb': array([40, 40, 40])}\n",
      "primary_600: {'hex': '121212', 'rgb': array([18, 18, 18])}\n",
      "primary_50: {'hex': '#979797', 'rgb': array([151, 151, 151])}\n",
      "primary_700: {'hex': '#-4-4-4', 'rgb': array([-4, -4, -4])}\n",
      "primary_800: {'hex': '#-1a-1a-1a', 'rgb': array([-26, -26, -26])}\n",
      "primary_900: {'hex': '#-30-30-30', 'rgb': array([-48, -48, -48])}\n",
      "primary_950: {'hex': '#-3b-3b-3b', 'rgb': array([-59, -59, -59])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    return np.array([int(hex_color[i:i+2], 16) for i in (0, 2, 4)])\n",
    "\n",
    "def rgb_to_hex(rgb_color):\n",
    "    return ''.join([f'{int(i):02x}' for i in rgb_color])\n",
    "\n",
    "def predict_colors(input_colors):\n",
    "    input_colors.reverse()  # Reverse the order of the input colors\n",
    "    weights = np.array(range(100, 700, 100))\n",
    "    colors_rgb = np.array([hex_to_rgb(color[1:]) for color in input_colors])\n",
    "\n",
    "    colors_hsv = np.array([mcolors.rgb_to_hsv(color/255) for color in colors_rgb])\n",
    "\n",
    "    predicted_colors = {f'primary_{i}': {'hex': rgb_to_hex(color), 'rgb': color} for i, color in zip(range(100, 700, 100), colors_rgb)}\n",
    "    for i in [50, 700, 800, 900, 950]:\n",
    "        f = interpolate.interp1d(weights, colors_hsv, axis=0, fill_value=\"extrapolate\", bounds_error=False)\n",
    "        predicted_color_hsv = f(i)\n",
    "        predicted_color_rgb = (mcolors.hsv_to_rgb(predicted_color_hsv) * 255).astype(int)\n",
    "        predicted_colors[f'primary_{i}'] = {'hex': '#' + rgb_to_hex(predicted_color_rgb), 'rgb': predicted_color_rgb}\n",
    "\n",
    "    return predicted_colors\n",
    "\n",
    "input_colors = ['#121212', '#282828', '#3f3f3f', '#575757', '#717171', '#8b8b8b']  # Example input\n",
    "# input_colors.reverse()\n",
    "predicted_colors = predict_colors(input_colors)\n",
    "for name, color in predicted_colors.items():\n",
    "    print(f'{name}: {color}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def rgb_to_hex(rgb_color):\n",
    "    return ''.join([f'{i:02x}' for i in rgb_color])\n",
    "\n",
    "def generate_colors(primary_950):\n",
    "    primary_950_rgb = hex_to_rgb(primary_950[1:])  # Remove the '#' at the start\n",
    "    primary_950_hls = colorsys.rgb_to_hls(*[x/255.0 for x in primary_950_rgb])\n",
    "\n",
    "    colors = {}\n",
    "    colors_rgb = {}\n",
    "    for i in range(50, 1000, 50):\n",
    "        weight = 1 - (i / 1000.0)  # Adjust the weight calculation\n",
    "        lighter_color_hls = (primary_950_hls[0], max(0, min(1, weight)), primary_950_hls[2])\n",
    "        lighter_color_rgb = [int(x*255.0) for x in colorsys.hls_to_rgb(*lighter_color_hls)]\n",
    "        colors_rgb[f'secondary_{i}'] = lighter_color_rgb\n",
    "        colors[f'secondary_{i}'] = '#' + rgb_to_hex(lighter_color_rgb)\n",
    "\n",
    "    return colors, colors_rgb\n",
    "\n",
    "primary_950 = '#121212'  # Example input\n",
    "colors, colors_rgb = generate_colors(primary_950)\n",
    "for name, color in colors.items():\n",
    "    print(f'{name}: {color}')\n",
    "\n",
    "for name, color in colors_rgb.items():\n",
    "    print(f'{name}: {color}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorsys import hsv_to_rgb, rgb_to_hsv\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def rgb_to_hex(rgb_color):\n",
    "    return ''.join([f'{i:02x}' for i in rgb_color])\n",
    "\n",
    "def predict_color(colors, target_shade):\n",
    "  \"\"\"Predicts a color for a given shade based on existing shades.\"\"\"\n",
    "  # Convert colors to HSV for easier manipulation\n",
    "  hues = [rgb_to_hsv(*hex_to_rgb(color))[0] for color in colors]\n",
    "\n",
    "  # Calculate average hue\n",
    "  average_hue = sum(hues) / len(hues)\n",
    "\n",
    "  # Calculate average saturation and value based on available shades\n",
    "  average_saturation = 0\n",
    "  average_value = 0\n",
    "  num_shades = 0\n",
    "  for color in colors:\n",
    "    rgb = hsv_to_rgb(*hex_to_rgb(color))  # Store the full RGB tuple\n",
    "    if rgb[0] and rgb[1] and rgb[2]:  # Check if all RGB values exist\n",
    "      average_saturation += rgb[1]\n",
    "      average_value += rgb[2]\n",
    "      num_shades += 1\n",
    "  if num_shades > 0:  # Only calculate averages if shades have complete info\n",
    "    average_saturation /= num_shades\n",
    "    average_value /= num_shades\n",
    "\n",
    "  # Calculate difference between target shade and existing shades\n",
    "  differences = [(abs(target_shade - hue), color) for hue, color in zip(hues, colors)]\n",
    "  closest_shade = min(differences, key=lambda x: x[0])[1]\n",
    "\n",
    "  # Use closest shade as reference and adjust hue based on desired difference\n",
    "  new_hue = average_hue + (target_shade - average_hue) * (hues[colors.index(closest_shade)] - average_hue)\n",
    "\n",
    "  # Calculate new color in HSV and convert back to RGB and hex\n",
    "  new_color_hsv = (new_hue, average_saturation, average_value)\n",
    "  new_color_rgb = hsv_to_rgb(*new_color_hsv)\n",
    "  new_color_hex = rgb_to_hex(new_color_rgb)\n",
    "\n",
    "  # Ensure new color stays within RGB range (0-255)\n",
    "  new_color_rgb = tuple(max(0, min(255, channel)) for channel in new_color_rgb)\n",
    "  new_color_hex = rgb_to_hex(new_color_rgb)\n",
    "\n",
    "  return new_color_rgb, new_color_hex\n",
    "\n",
    "def generate_palette(input_colors):\n",
    "  \"\"\"Generates missing colors in a color palette.\"\"\"\n",
    "  shades = [\"50\", \"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\", \"900\", \"950\"]\n",
    "  palette = {shade: None for shade in shades}\n",
    "\n",
    "  for shade in input_colors:\n",
    "    palette[shade] = input_colors[shade]\n",
    "\n",
    "  for shade in shades:\n",
    "    if palette[shade] is None:\n",
    "      color_rgb, color_hex = predict_color([palette[s] for s in shades if palette[s] is not None], int(shade))\n",
    "      palette[shade] = (color_rgb, color_hex)\n",
    "\n",
    "  return palette\n",
    "\n",
    "# Example usage\n",
    "input_colors = {\n",
    "  \"100\": \"#382bf0\",\n",
    "  \"200\": \"#5e43f3\",\n",
    "  \"300\": \"#7a5af5\",\n",
    "  \"400\": \"#9171f8\",\n",
    "  \"500\": \"#a688fa\",\n",
    "  \"600\": \"#ba9ffb\",\n",
    "}\n",
    "\n",
    "palette = generate_palette(input_colors)\n",
    "\n",
    "for shade, (rgb, hex) in palette.items():\n",
    "  print(f\"Shade {shade}:\")\n",
    "  print(f\"  RGB: {rgb}\")\n",
    "  print(f\"  Hex: {hex}\")\n",
    "  print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lip-wise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
