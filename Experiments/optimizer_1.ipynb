{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is a part of https://github.com/pawansharmaaaa/Lip_Wise/ repository.\n",
    "import gradio as gr\n",
    "\n",
    "# Custom Modules\n",
    "# import infer\n",
    "import file_check\n",
    "\n",
    "bg_upscalers = list(file_check.REAL_ESRGAN_MODEL_URL.keys())\n",
    "\n",
    "def render_dd(bg_upscale):\n",
    "    \n",
    "    return gr.Dropdown(\n",
    "                        choices=bg_upscalers,\n",
    "                        label=\"REALESRGAN Model\",\n",
    "                        value=\"RealESRGAN_x2plus\",\n",
    "                        info=\"Choose the model to use for upscaling the background.\",\n",
    "                        # Initially disabled and hidden\n",
    "                        visible=bg_upscale\n",
    "                    )\n",
    "\n",
    "def render_weight(face_restorer):\n",
    "    if face_restorer == \"CodeFormer\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.3,\n",
    "                            label=\"CodeFormer Weight\",\n",
    "                            info=\"0 for better quality, 1 for better identity.\",\n",
    "                            scale=2,\n",
    "                            visible=True\n",
    "                        )\n",
    "    elif face_restorer == \"GFPGAN\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.5,\n",
    "                            label=\"GFPGAN Weight\",\n",
    "                            info=\"0 for better identity, 1 for better quality.\",\n",
    "                            scale=2,\n",
    "                            visible=True\n",
    "                        )\n",
    "    elif face_restorer == \"RestoreFormer\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.5,\n",
    "                            label=\"RestoreFormer Weight\",\n",
    "                            info=\"0 for better identity, 1 for better quality.\",\n",
    "                            scale=2,\n",
    "                            visible=True\n",
    "                        )\n",
    "    elif face_restorer == \"None\":\n",
    "        return gr.Slider(\n",
    "                            minimum=0.0,\n",
    "                            maximum=1.0,\n",
    "                            step=0.1,\n",
    "                            value=0.0,\n",
    "                            label=\"Weight\",\n",
    "                            info=\"0 for better identity, 1 for better quality.\",\n",
    "                            scale=2,\n",
    "                            visible=False\n",
    "                        )\n",
    "    \n",
    "# Theme\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=gr.themes.Color(c100=\"#efe7ff\", c200=\"#decefe\", c300=\"#ccb7fd\", c400=\"#ba9ffc\", c50=\"#ffffff\", c500=\"#a688fa\", c600=\"#836bc3\", c700=\"#61508e\", c800=\"#41365d\", c900=\"#241e30\", c950=\"#25242a\"),\n",
    "    secondary_hue=gr.themes.Color(c100=\"#e2e1e4\", c200=\"#c6c5c9\", c300=\"#aba9b0\", c400=\"#908d96\", c50=\"#ffffff\", c500=\"#76737e\", c600=\"#5e5b64\", c700=\"#46444b\", c800=\"#302f33\", c900=\"#1b1b1d\", c950=\"#25242a\"),\n",
    "    neutral_hue=gr.themes.Color(c100=\"#e1e1e1\", c200=\"#c4c4c4\", c300=\"#a7a7a7\", c400=\"#8c8c8c\", c50=\"#ffffff\", c500=\"#717171\", c600=\"#5a5a5a\", c700=\"#434343\", c800=\"#2e2e2e\", c900=\"#25242a\", c950=\"#1b1b1b\"),\n",
    "    spacing_size=\"md\",\n",
    "    radius_size=\"lg\",\n",
    ").set(\n",
    "    shadow_drop='*shadow_inset',\n",
    "    shadow_drop_lg='*button_shadow_hover',\n",
    "    body_background_fill=\"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(255,255,255,1) 0.3%, rgba(255,255,255,1) 90.2% );\",\n",
    "    # body_background_fill_dark=\"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(0,0,0,1) 60%, rgba(250,250,250,1) 80% );\",\n",
    "    # body_background_fill_dark='''url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400' viewBox='0 0 800 800'%3E%3Cg fill='none' stroke='%23404' stroke-width='1'%3E%3Cpath d='M769 229L1037 260.9M927 880L731 737 520 660 309 538 40 599 295 764 126.5 879.5 40 599-197 493 102 382-31 229 126.5 79.5-69-63'/%3E%3Cpath d='M-31 229L237 261 390 382 603 493 308.5 537.5 101.5 381.5M370 905L295 764'/%3E%3Cpath d='M520 660L578 842 731 737 840 599 603 493 520 660 295 764 309 538 390 382 539 269 769 229 577.5 41.5 370 105 295 -36 126.5 79.5 237 261 102 382 40 599 -69 737 127 880'/%3E%3Cpath d='M520-140L578.5 42.5 731-63M603 493L539 269 237 261 370 105M902 382L539 269M390 382L102 382'/%3E%3Cpath d='M-222 42L126.5 79.5 370 105 539 269 577.5 41.5 927 80 769 229 902 382 603 493 731 737M295-36L577.5 41.5M578 842L295 764M40-201L127 80M102 382L-261 269'/%3E%3C/g%3E%3Cg fill='%23505'%3E%3Ccircle cx='769' cy='229' r='5'/%3E%3Ccircle cx='539' cy='269' r='5'/%3E%3Ccircle cx='603' cy='493' r='5'/%3E%3Ccircle cx='731' cy='737' r='5'/%3E%3Ccircle cx='520' cy='660' r='5'/%3E%3Ccircle cx='309' cy='538' r='5'/%3E%3Ccircle cx='295' cy='764' r='5'/%3E%3Ccircle cx='40' cy='599' r='5'/%3E%3Ccircle cx='102' cy='382' r='5'/%3E%3Ccircle cx='127' cy='80' r='5'/%3E%3Ccircle cx='370' cy='105' r='5'/%3E%3Ccircle cx='578' cy='42' r='5'/%3E%3Ccircle cx='237' cy='261' r='5'/%3E%3Ccircle cx='390' cy='382' r='5'/%3E%3C/g%3E%3C/svg%3E\");''',\n",
    "    # background_fill_primary_dark=\"#330033\"\n",
    "    # body_background_fill_dark= '''linear-gradient(to bottom right, #151515 50%, #201c20 100%, #ffffff);'''\n",
    "    # body_background_fill_dark= \"linear-gradient(315deg, #7f5a83 0%, #0d324d 74%);\"\n",
    "\n",
    "    # body_background_fill_dark= \"radial-gradient( circle farthest-corner at -4% -12.9%,  rgba(74,98,110,1) 0.3%, rgba(30,33,48,1) 90.2% );\",\n",
    "    # body_background_fill_dark= \"-webkit-linear-gradient(to right, #2C5364, #203A43, #0F2027);\",\n",
    "    # body_background_fill_dark= \"linear-gradient(to right, #2C5364, #203A43, #0F2027);\"\n",
    ")\n",
    "\n",
    "head_html = f'''\n",
    "<head class>\n",
    "  <meta author=\"Pawan Sharma\">\n",
    "  <meta charset=\"utf-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "</head>\n",
    "'''\n",
    "\n",
    "# Create interface\n",
    "\n",
    "with gr.Blocks(title='Lip-Wise', css=r\"/home/thesus/Documents/Lip_Wise/style-black.css\", head=head_html, theme=theme) as demo:\n",
    "    with gr.Row(elem_classes=[\"row\"]):\n",
    "        gr.HTML(\n",
    "            '''\n",
    "            <header>\n",
    "            <div class=\"header-left\">\n",
    "                <h1>Lip Wise</h1>\n",
    "                <h2>Wise Enhancements for Wav2Lip</h2>\n",
    "            </div>\n",
    "            <div class=\"header-right\">\n",
    "                <img src=\"https://github.com/pawansharmaaaa/Lip_Wise/assets/56242483/5bc1b8af-879a-414b-b54a-db605a53c8f7\" alt=\"Logo\">\n",
    "            </div>\n",
    "            </header>\n",
    "            '''\n",
    "        )\n",
    "    with gr.Tab(label=\"Process Image\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Row(elem_classes=[\"row\"]):\n",
    "            with gr.Column():\n",
    "                # gr.Markdown(\"# INPUTS\")\n",
    "                with gr.Accordion(label=\"Input Image and Audio\", open=True, elem_classes=[\"inp_group\", \"accordion\"]):\n",
    "                    image_input = gr.Image(type=\"filepath\", \n",
    "                                           label=\"Image\", \n",
    "                                           container=True, \n",
    "                                           elem_id = \"inp_group\")\n",
    "                    audio_input = gr.Audio(type=\"filepath\", \n",
    "                                           label=\"Audio\", \n",
    "                                           container=True, \n",
    "                                           elem_id = \"inp_group\")\n",
    "                    process = gr.Button(value=\"Begin Processing\", \n",
    "                                        variant=\"primary\", \n",
    "                                        elem_id=\"gen-button\")\n",
    "                    \n",
    "            with gr.Column():\n",
    "                # gr.Markdown(\"# OUTPUT\")\n",
    "                image_output = gr.Video(sources='upload', \n",
    "                                        label=\"Output\", \n",
    "                                        elem_classes=[\"output\"],\n",
    "                                        container=True)\n",
    "\n",
    "        with gr.Accordion(label=\"Options\", open=True, elem_classes=[\"opt_group\", \"accordion\"]):\n",
    "            with gr.Group():\n",
    "                with gr.Column(variant=\"default\"):\n",
    "                    with gr.Row( variant=\"compact\"):\n",
    "                        gan = gr.Checkbox(label = \"Use Wav2Lip_GAN?\", \n",
    "                                        value=False, \n",
    "                                        info=\"This will use Wav2Lip_GAN instead of Wav2Lip. May get better results in some cases\", \n",
    "                                        interactive=True,\n",
    "                                        elem_classes=[\"option\"])\n",
    "                        alignment = gr.Checkbox(label = \"Perform 3D_alignment\", \n",
    "                                                info = \"This will improve the quality of the lip sync, but the output will be different from the original video.\",\n",
    "                                                elem_classes=[\"option\"])\n",
    "                    \n",
    "                    with gr.Row(variant=\"compact\"):\n",
    "                        fps = gr.Slider(minimum=1, \n",
    "                                        maximum=60, \n",
    "                                        step=1, \n",
    "                                        value=25, \n",
    "                                        label=\"FPS\", \n",
    "                                        info=\"Desired Frames per second (FPS) of the output video.\",\n",
    "                                        elem_classes=[\"option\"])\n",
    "                        padding = gr.Slider(minimum=0, \n",
    "                                            maximum=60, \n",
    "                                            step=1, \n",
    "                                            value=0, \n",
    "                                            label=\"Padding\", \n",
    "                                            info=\"Increase if getting black outlines. The Value is in Pixels.\",\n",
    "                                            elem_classes=[\"option\"]) \n",
    "                        \n",
    "                with gr.Column(variant=\"compact\"):\n",
    "                    with gr.Row():\n",
    "                        face_restorer = gr.Radio([\"GFPGAN\", \"CodeFormer\", \"RestoreFormer\", \"None\"], \n",
    "                                                value='CodeFormer', \n",
    "                                                label=\"Face Restorer\", \n",
    "                                                info=\"GFPGAN is faster, but CodeFormer is more accurate.\", \n",
    "                                                interactive=True,\n",
    "                                                elem_classes=[\"option\"])\n",
    "                        weight = gr.Slider(minimum=0.0,\n",
    "                                        maximum=1.0,\n",
    "                                        step=0.1,\n",
    "                                        value=0.3,\n",
    "                                        label=\"CodeFormer Weight\",\n",
    "                                        info=\"0 for better quality, 1 for better identity.\",\n",
    "                                        scale=2,\n",
    "                                        elem_classes=[\"option\"])\n",
    "                        \n",
    "                    with gr.Row():\n",
    "                        upscale_bg = gr.Checkbox(label = \"Upscale Background with REALESRGAN\", \n",
    "                                                value=False, \n",
    "                                                info=\"This will improve the quality of the video, but will take longer to process.\",\n",
    "                                                elem_classes=[\"option\"])\n",
    "                        \n",
    "                        bg_model = gr.Dropdown(choices=bg_upscalers, \n",
    "                                            label=\"REALESRGAN Model\", \n",
    "                                            value=\"RealESRGAN_x2plus\", \n",
    "                                            info=\"Choose the model to use for upscaling the background.\", \n",
    "                                            visible=False,\n",
    "                                            scale=2,\n",
    "                                            elem_classes=[\"option\"])\n",
    "                        \n",
    "                        mel_step_size = gr.Number(value=16, label=\"Mel Step Size\", interactive=False, visible=False)\n",
    "                \n",
    "                upscale_bg.select(render_dd, upscale_bg, bg_model)\n",
    "                face_restorer.select(render_weight, face_restorer, weight)\n",
    "        \n",
    "        inputs = [image_input, audio_input, padding, alignment, face_restorer, fps, mel_step_size, weight, upscale_bg, bg_model, gan]\n",
    "        print(inputs)\n",
    "        # process.click(infer.infer_image, [image_input, audio_input, padding, alignment, face_restorer, fps, mel_step_size, weight, upscale_bg, bg_model], [image_output])\n",
    "\n",
    "    with gr.Tab(label=\"Process Video\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Row(elem_classes=[\"row\"]):\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# INPUTS\")\n",
    "                with gr.Accordion(\"Input Video and Audio\", open=True, elem_classes=[\"inp_group\", \"accordion\"]):\n",
    "                    video_input = gr.Video(sources='upload',\n",
    "                                           label=\"Video\")\n",
    "                    audio_input = gr.Audio(type=\"filepath\", \n",
    "                                           label=\"Audio\")\n",
    "                    process = gr.Button(value=\"Process Video\", \n",
    "                                        variant=\"primary\", \n",
    "                                        elem_id=\"gen-button\")\n",
    "                    \n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"# OUTPUT\")\n",
    "                video_output = gr.Video(sources='upload', \n",
    "                                        label=\"Output\", \n",
    "                                        elem_classes=[\"output\"])\n",
    "                \n",
    "        with gr.Accordion(label=\"Options\", open=True, elem_classes=[\"opt_group\", \"accordion\"]):\n",
    "            with gr.Group():\n",
    "                with gr.Column(variant=\"panel\"):\n",
    "                    with gr.Row():\n",
    "                        gan = gr.Checkbox(label = \"Use Wav2Lip_GAN\", \n",
    "                                        value=False, \n",
    "                                        info=\"This will use Wav2Lip_GAN instead of Wav2Lip. May get better results in some cases\", \n",
    "                                        interactive=True)\n",
    "                        loop = gr.Checkbox(label = \"Loop Video\", \n",
    "                                        value=False, \n",
    "                                        info=\"This will loop the video to the length of the audio file.\", \n",
    "                                        interactive=True)\n",
    "                        \n",
    "                    padding = gr.Slider(minimum=0, \n",
    "                                        maximum=60, \n",
    "                                        step=1, \n",
    "                                        value=0, \n",
    "                                        label=\"Padding\", \n",
    "                                        info=\"Increase if getting black outlines. The Value is in Pixels.\", \n",
    "                                        elem_id=\"slider\")\n",
    "                \n",
    "                with gr.Column(variant=\"panel\"):\n",
    "                    with gr.Row():           \n",
    "                        face_restorer = gr.Radio([\"GFPGAN\", \"CodeFormer\", \"RestoreFormer\", \"None\"],\n",
    "                                                value='CodeFormer', \n",
    "                                                label=\"Face Restorer\", \n",
    "                                                info=\"GFPGAN is faster, but CodeFormer is more accurate.\")\n",
    "                        \n",
    "                        weight = gr.Slider(minimum=0.0,\n",
    "                                            maximum=1.0,\n",
    "                                            step=0.1,\n",
    "                                            value=0.3,\n",
    "                                            label=\"CodeFormer Weight\",\n",
    "                                            info=\"0 for better quality, 1 for better identity.\",\n",
    "                                            scale=2)\n",
    "                    \n",
    "                    mel_step_size = gr.Number(value=16, \n",
    "                                              label=\"Mel Step Size\", \n",
    "                                              interactive=False, \n",
    "                                              visible=False)\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        upscale_bg = gr.Checkbox(label = \"Upscale Background with REALESRGAN\", \n",
    "                                                value=False, \n",
    "                                                info=\"This will improve the quality of the video, but will take longer to process.\")\n",
    "                        bg_model = gr.Dropdown(choices=bg_upscalers, \n",
    "                                            label=\"REALESRGAN Model\", \n",
    "                                            value=\"RealESRGAN_x2plus\", \n",
    "                                            info=\"Choose the model to use for upscaling the background.\", \n",
    "                                            visible=False,\n",
    "                                            interactive=True,\n",
    "                                            scale=2)\n",
    "                    \n",
    "                    upscale_bg.select(render_dd, upscale_bg, bg_model)\n",
    "                    face_restorer.select(render_weight, face_restorer, weight)\n",
    "\n",
    "                # process.click(infer.infer_video, [video_input, audio_input, padding, face_restorer, mel_step_size, weight, upscale_bg, bg_model], [video_output])\n",
    "\n",
    "    with gr.Tab(label=\"Guide\", elem_id=\"tab\", elem_classes=[\"tabs\"]):\n",
    "        with gr.Accordion(label=\"Tips For Better Results\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > - Optimal performance is achieved with a **clear image** featuring a person facing the camera, regardless of head angle. However, avoid **tilting in the z-direction** (3D-alignment can address this with certain considerations).\n",
    "            > - Ensure the image contains only **one person** with a prominently visible face.\n",
    "            > - Clear audio devoid of background noise enhances results significantly.\n",
    "            > - Note that **higher image resolution** necessitates **additional processing time**.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"Model Selection\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > ##### **CODEFORMER:**\n",
    "            >**Recommended Weight:** `0 for better quality, 1 for better identity.`\n",
    "            >>- CodeFormer employs a transformative architecture to restore facial features.\n",
    "            >>- While relatively slower, it boasts **higher accuracy**.\n",
    "            >>- Generally delivers superior results while **preserving skin texture**.\n",
    "            >>- In cases of peculiar artifacts, especially around the nose, consider using GFPGAN.\n",
    "            \n",
    "            > ##### **GFPGAN:**\n",
    "            >**Recommended Weight:** `0 for better identity, 1 for better quality.`\n",
    "            >>- GFPGAN, a faster model, relies on a GAN-based framework for facial restoration.\n",
    "            >>- Suggested for use **when CodeFormer exhibits undesirable artifacts**.\n",
    "            >>- However, it often sacrifices skin texture fidelity.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"3D Alignment\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > Enabling this feature **transforms** the image to ensure the person faces the camera directly. While enhancing lip sync quality, the output may diverge from the original video.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "        with gr.Accordion(label=\"Background Upscaling\", open=True, elem_classes=[\"guide\"]):\n",
    "            gr.Markdown(\n",
    "            \"\"\"\n",
    "            > - Activating this feature **enhances video quality** but prolongs processing time.\n",
    "            > - For most scenarios, RealESRGAN_x2plus is preferable due to its comparative speed.\n",
    "            > - Optimal results are achieved when combined with CodeFormer, except in cases of nose-related artifacts.\n",
    "            > - This feature effectively **eliminates video flickering**.\n",
    "            \"\"\",\n",
    "            line_breaks=True)\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background-color: #330033;\n",
    "background-image: url(\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400' viewBox='0 0 800 800'%3E%3Cg fill='none' stroke='%23404' stroke-width='1'%3E%3Cpath d='M769 229L1037 260.9M927 880L731 737 520 660 309 538 40 599 295 764 126.5 879.5 40 599-197 493 102 382-31 229 126.5 79.5-69-63'/%3E%3Cpath d='M-31 229L237 261 390 382 603 493 308.5 537.5 101.5 381.5M370 905L295 764'/%3E%3Cpath d='M520 660L578 842 731 737 840 599 603 493 520 660 295 764 309 538 390 382 539 269 769 229 577.5 41.5 370 105 295 -36 126.5 79.5 237 261 102 382 40 599 -69 737 127 880'/%3E%3Cpath d='M520-140L578.5 42.5 731-63M603 493L539 269 237 261 370 105M902 382L539 269M390 382L102 382'/%3E%3Cpath d='M-222 42L126.5 79.5 370 105 539 269 577.5 41.5 927 80 769 229 902 382 603 493 731 737M295-36L577.5 41.5M578 842L295 764M40-201L127 80M102 382L-261 269'/%3E%3C/g%3E%3Cg fill='%23505'%3E%3Ccircle cx='769' cy='229' r='5'/%3E%3Ccircle cx='539' cy='269' r='5'/%3E%3Ccircle cx='603' cy='493' r='5'/%3E%3Ccircle cx='731' cy='737' r='5'/%3E%3Ccircle cx='520' cy='660' r='5'/%3E%3Ccircle cx='309' cy='538' r='5'/%3E%3Ccircle cx='295' cy='764' r='5'/%3E%3Ccircle cx='40' cy='599' r='5'/%3E%3Ccircle cx='102' cy='382' r='5'/%3E%3Ccircle cx='127' cy='80' r='5'/%3E%3Ccircle cx='370' cy='105' r='5'/%3E%3Ccircle cx='578' cy='42' r='5'/%3E%3Ccircle cx='237' cy='261' r='5'/%3E%3Ccircle cx='390' cy='382' r='5'/%3E%3C/g%3E%3C/svg%3E\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "def long_running_task(name):\n",
    "    import time\n",
    "    for i in range(2):\n",
    "        print(f\"Iteration {i} for {name}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    return \"Task completed!\"\n",
    "\n",
    "def clear_selected():\n",
    "  return None, None\n",
    "\n",
    "def make_visible(gradio_component):\n",
    "  return gradio_component(visible=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    name_input = gr.Textbox(label=\"Enter your name\")\n",
    "    output = gr.Textbox(label=\"Output\", visible=False)\n",
    "    start_button = gr.Button(\"Start Long Task\")\n",
    "    clear_button = gr.ClearButton(name_input, value=\"Clear\")\n",
    "\n",
    "    # Event Listeners (where the magic happens)\n",
    "    event = start_button.click(make_visible, inputs=output, outputs=output)\n",
    "\n",
    "demo.queue().launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def sum_consecutive_elements(lst, progress = gr.Progress()):\n",
    "    result = []\n",
    "    for i in range(0, len(lst) - 1, 2):\n",
    "        time.sleep(0.5)\n",
    "        result.append(lst[i] + lst[i + 1])\n",
    "        progress.__call__((i, len(lst)), desc=f\"Adding {lst[i]} and {lst[i + 1]}\")\n",
    "    if len(lst) % 2 != 0:\n",
    "        result.append(lst[-1])\n",
    "    return result\n",
    "\n",
    "def load_data(pro=gr.Progress()):\n",
    "    pro.__call__((0, 100), desc=\"Loading data...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "def good(num):\n",
    "    p = gr.Progress()\n",
    "    n=0\n",
    "    a = list()\n",
    "    while(n!=num):\n",
    "        a.append(n)\n",
    "        p.__call__((n, num), desc=f\"Appending {n} to list\")\n",
    "        time.sleep(0.5)\n",
    "        n+=1\n",
    "\n",
    "        if n==num:\n",
    "            break\n",
    "    \n",
    "    load_data()\n",
    "    \n",
    "    a = sum_consecutive_elements(a)\n",
    "\n",
    "    q = gr.Progress()\n",
    "    for i in q.tqdm(a, desc=f\"Reading consecutive elements\", total=len(a)):\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return \"Done\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    num = gr.Number(label=\"Number\")\n",
    "    text = gr.Textbox(label=\"Output\")\n",
    "    button = gr.Button(\"Start\")\n",
    "\n",
    "    button.click(good, inputs=num, outputs=text)\n",
    "\n",
    "demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from pydub.utils import mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/thesus/Documents/Tests/video.mp4\"\n",
    "dest_path = \"/home/thesus/Documents/Tests/out3.mp4\"\n",
    "audio_path = \"/home/thesus/Documents/Tests/audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.VideoCapture(\"/home/thesus/Documents/Tests/video.mp4\")\n",
    "dest = cv2.VideoCapture(\"/home/thesus/Documents/Tests/out.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_frames = int(src.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "no_of_frames_dest = int(dest.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 6677\n"
     ]
    }
   ],
   "source": [
    "print(no_of_frames, no_of_frames_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_duration(file_path):\n",
    "    info = mediainfo(file_path)\n",
    "    duration = info['duration']\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 67.317583 seconds\n"
     ]
    }
   ],
   "source": [
    "duration = get_audio_duration(\"/home/thesus/Documents/Tests/audio.wav\")\n",
    "print(f'Duration: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 3.0 seconds\n",
      "Duration: 278.2083333333333 seconds\n"
     ]
    }
   ],
   "source": [
    "duration_src = src.get(cv2.CAP_PROP_FRAME_COUNT) / src.get(cv2.CAP_PROP_FPS)\n",
    "duration_dest = dest.get(cv2.CAP_PROP_FRAME_COUNT) / dest.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f'Duration: {duration_src} seconds')\n",
    "print(f'Duration: {duration_dest} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 67.317583 seconds\n",
      "Duration: 3.000000 seconds\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version n6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13.2.1 (GCC) 20230801\n",
      "  configuration: --prefix=/usr --disable-debug --disable-static --disable-stripping --enable-amf --enable-avisynth --enable-cuda-llvm --enable-lto --enable-fontconfig --enable-frei0r --enable-gmp --enable-gnutls --enable-gpl --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libdav1d --enable-libdrm --enable-libfreetype --enable-libfribidi --enable-libgsm --enable-libharfbuzz --enable-libiec61883 --enable-libjack --enable-libjxl --enable-libmodplug --enable-libmp3lame --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libplacebo --enable-libpulse --enable-librav1e --enable-librsvg --enable-librubberband --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libv4l2 --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpl --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxcb --enable-libxml2 --enable-libxvid --enable-libzimg --enable-nvdec --enable-nvenc --enable-opencl --enable-opengl --enable-shared --enable-vapoursynth --enable-version3 --enable-vulkan\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, nut, from 'fd:':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42isom\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: N/A, start: 0.083333, bitrate: N/A\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1024x576, 24 fps, 24 tbr, 49152 tbn (default)\n",
      "    Metadata:\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[mp3 @ 0x56d3f09957c0] Estimating duration from bitrate, this may be inaccurate\n",
      "Input #1, mp3, from '/home/thesus/Documents/Tests/audio.wav':\n",
      "  Duration: 00:01:07.32, start: 0.000000, bitrate: 96 kb/s\n",
      "  Stream #1:0: Audio: mp3, 44100 Hz, mono, fltp, 96 kb/s\n",
      "Output #0, mp4, to '/home/thesus/Documents/Tests/out3.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42isom\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1024x576, q=2-31, 24 fps, 24 tbr, 49152 tbn (default)\n",
      "    Metadata:\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: mp3 (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 96 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (copy)\n",
      "[out#0/mp4 @ 0x56d3f0a8d9c0] video:3590kB audio:789kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.255256%\n",
      "size=    4434kB time=00:01:07.87 bitrate= 535.1kbits/s speed=2.27e+03x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_audio_duration(file_path):\n",
    "    info = mediainfo(file_path)\n",
    "    duration = info['duration']\n",
    "    return duration\n",
    "\n",
    "# Replace 'audio.mp3' and 'video.mp4' with your actual file paths\n",
    "audio_duration = get_audio_duration(audio_path)\n",
    "video_duration = get_audio_duration(src_path)\n",
    "\n",
    "print(f'Duration: {audio_duration} seconds')\n",
    "print(f'Duration: {video_duration} seconds')\n",
    "\n",
    "loops = math.ceil(float(audio_duration) / float(video_duration))\n",
    "print(loops)\n",
    "\n",
    "os.system(f\"ffmpeg -stream_loop {loops} -i {src_path} -c copy -v 0 -f nut - | ffmpeg -thread_queue_size 10K -i - -i {audio_path} -c copy -map 0:v -map 1:a -shortest -y {dest_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lip-wise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
